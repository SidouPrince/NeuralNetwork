{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtFEx5GZIdul4z0BBL04KI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SidouPrince/NeuralNetwork/blob/main/Anglais_Fran%C3%A7ais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlINy-sWpgvD"
      },
      "source": [
        "#LOAD & CLEANING DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyAsKUIWpcM6"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import pysrt\n",
        "import re\n",
        "#from helper import load_data\n",
        "\n",
        "import os, sys\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjOttd_gM6h-"
      },
      "source": [
        "!pip install pysrt\n",
        "!pip install helper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVSQDdT6Meqb"
      },
      "source": [
        "def load_english_sentences(file_name):\n",
        "  english_sentences = []\n",
        "  english_sentences_file = open(file_name)\n",
        "  for sentence in english_sentences_file:\n",
        "    english_sentences.append(sentence)\n",
        "  return english_sentences\n",
        "\n",
        "def load_french_sentences(file_name):\n",
        "  french_sentences = []\n",
        "  french_sentences_file = open(file_name)\n",
        "  for sentence in french_sentences_file:\n",
        "    french_sentences.append(sentence)\n",
        "  return french_sentences"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFgtRO9ZSykM"
      },
      "source": [
        "english_sentences = load_english_sentences('/content/small_vocab_en.txt')\n",
        "french_sentences = load_french_sentences('/content/small_vocab_fr.txt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC7ynWjSMgBj",
        "outputId": "80caaadd-8ab2-44ad-a2eb-958d7894947a"
      },
      "source": [
        "print(english_sentences[1])\n",
        "print(\"La traduction corespondante\")\n",
        "print(french_sentences[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the united states is usually chilly during july , and it is usually freezing in november .\n",
            "\n",
            "La traduction corespondante\n",
            "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTiafIgCR9lT",
        "outputId": "8a7bea24-34fe-4cac-ce07-cdfb054e66a5"
      },
      "source": [
        "#La longueuur des deux fichier\n",
        "print(len(english_sentences))\n",
        "print(len(french_sentences))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137860\n",
            "137860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWt258tgTnF9"
      },
      "source": [
        "english_words_counter = Counter([word for sentence in english_sentences for word in sentence.split()])\n",
        "french_words_counter = Counter([word for sentence in french_sentences for word in sentence.split()])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iEAy5f-Vfls",
        "outputId": "cb9bbd8e-7e94-46af-db7b-cea516564059"
      },
      "source": [
        "print(\"English words {}\".format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
        "print(\"English unique words {}\".format(len(english_words_counter)))\n",
        "print(\"10 most common words in english\")\n",
        "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
        "print()\n",
        "print(\"French words {}\".format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
        "print(\"French unique words {}\".format(len(french_words_counter)))\n",
        "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English words 1823250\n",
            "English unique words 227\n",
            "10 most common words in english\n",
            "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
            "\n",
            "French words 1961295\n",
            "French unique words 355\n",
            "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBSc39ZedWos"
      },
      "source": [
        "def tokenize(x):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(x)\n",
        "  tok = tokenizer.texts_to_sequences(x)\n",
        "  return tok, tokenizer\n",
        "\n",
        "  \n",
        "def pad(data, length=None):\n",
        "  padding = tf.keras.preprocessing.sequence.pad_sequences(data, padding='post', maxlen=length)\n",
        "  return padding"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAvvxCwDNrvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e675ef68-5556-4633-819a-2acaaae20cec"
      },
      "source": [
        "text_sentences = [\n",
        "    'The quick brown fox jumps over the lazy dog .',\n",
        "    'By Jove , my quick study of lexicography won a prize .',\n",
        "    'This is a short sentence .']\n",
        "\n",
        "tokenized, tokenizer = tokenize(text_sentences)\n",
        "test_pad = pad(tokenized)\n",
        "\n",
        "for sample_i, (token_sent, pad_sent) in enumerate(zip(tokenized, test_pad)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(np.array(token_sent)))\n",
        "    print('  Output: {}'.format(pad_sent))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 1 in x\n",
            "  Input:  [1 2 4 5 6 7 1 8 9]\n",
            "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
            "Sequence 2 in x\n",
            "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
            "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
            "Sequence 3 in x\n",
            "  Input:  [18 19  3 20 21]\n",
            "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZAsSA4OOBK0",
        "outputId": "29f4c5f4-fa98-4e79-ea2b-90905a639ddb"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fApoN2RUYYeJ"
      },
      "source": [
        "import torchtext\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import io\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3K3UAOh5Rvl"
      },
      "source": [
        "def load_sentences(file_name):\n",
        "  sentences = []\n",
        "  sentences_file = open(file_name)\n",
        "  for sentence in sentences_file:\n",
        "    sentences.append(sentence)\n",
        "  return sentences"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDpry8e_Ylf8"
      },
      "source": [
        "\n",
        "pathAllVocab = ['/content/small_vocab_en.txt', '/content/small_vocab_fr.txt']\n",
        "trainPaths = [ '/content/small_vocab_en_train.txt',   '/content/small_vocab_fr_train.txt']\n",
        "testPaths = ['/content/small_vocab_en_test.txt', '/content/small_vocab_fr_test.txt']\n",
        "validationPaths = ['/content/small_vocab_en_validate.txt',  '/content/small_vocab_fr_validate.txt']\n",
        "\n",
        "\n",
        "_,fr_tokenizer = tokenize(load_sentences(pathAllVocab[1]))\n",
        "_,en_tokenizer = tokenize(load_sentences(pathAllVocab[0]))\n",
        "fr_vocab = fr_tokenizer.word_index\n",
        "en_vocab = en_tokenizer.word_index\n",
        "\n",
        "\n",
        "def data_process(filePath):\n",
        "\n",
        "  frData = []\n",
        "  enData = []\n",
        "  myData = []\n",
        "\n",
        "  #French sentences\n",
        "  french_sentences = load_sentences(filePath[1])\n",
        "  tokenized_fr_sentences,_ = tokenize(french_sentences)\n",
        "  padded_fr = pad(tokenized_fr_sentences, 21)\n",
        "\n",
        "  #English sentences\n",
        "  english_sentences = load_sentences(filePath[0])\n",
        "  tokenized_en_sentences,_ = tokenize(english_sentences)\n",
        "  padded_en = pad(tokenized_en_sentences, 21)\n",
        "  return padded_en, padded_fr\n",
        "\n",
        "preproc_en_train, preproc_fr_train = data_process(trainPaths)\n",
        "preproc_en_val, preproc_fr_val = data_process(validationPaths)\n",
        "preproc_en_test, preproc_fr_test = data_process(testPaths)\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z18QpWWbblay"
      },
      "source": [
        "french_vocab_size = len(fr_vocab)\n",
        "english_vocab_size = len(en_vocab)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsHdh1QI5Pie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2267ebd-ab13-49e6-aa55-da28b499ec1a"
      },
      "source": [
        "print(preproc_fr_train.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80000, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2yx_q9nB3kH"
      },
      "source": [
        "tmp = pad(preproc_en_train, 20)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5XLHH-fSEtK",
        "outputId": "d27ed028-d818-40f7-9781-6f415aecb936"
      },
      "source": [
        "tmp.shape\n",
        "tmp = tmp.reshape((-1, preproc_fr_train.shape[-2], 1))\n",
        "print(tmp.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 80000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaAgoaDVTMzG",
        "outputId": "1903ca36-30ef-4b70-9f7b-26dd7cd64c5f"
      },
      "source": [
        "tmp_y = preproc_fr_train.reshape((preproc_fr_train.shape[-2],-1, 1))\n",
        "print(tmp_y.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80000, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaKu_jh-hG5Y"
      },
      "source": [
        "max_french_sequence_length = 20\n",
        "max_french_sequence_length = 15"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz_-s5QFcgrK"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MroB6zg4cilZ"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, TimeDistributed, Dense,Embedding\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_eabXuzcnAk",
        "outputId": "9bb97e71-928e-477a-ad2d-d1c8f0550ff9"
      },
      "source": [
        "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \n",
        "   \n",
        "    model = Sequential([GRU(100,input_shape=(21,1),return_sequences=True),TimeDistributed(Dense(345,activation='softmax'))])\n",
        "\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(0.001))\n",
        "    return model\n",
        "tmp_x = preproc_en_train.reshape((preproc_fr_train.shape[-2],-1, 1))\n",
        "tmp_y = preproc_fr_train.reshape((preproc_fr_train.shape[-2],-1, 1))\n",
        "\n",
        "\n",
        "\n",
        "tmp_x_val = preproc_en_val.reshape((preproc_fr_val.shape[-2],-1, 1))\n",
        "tmp_y_val = preproc_fr_val.reshape((preproc_fr_val.shape[-2],-1, 1))\n",
        "# Train the neural network\n",
        "simple_rnn_model = simple_model(\n",
        "    tmp_x.shape,\n",
        "    max_french_sequence_length,\n",
        "    199,\n",
        "    344)\n",
        "simple_rnn_model.summary()\n",
        "history = simple_rnn_model.fit(tmp_x, tmp_y, epochs=10,batch_size=900,validation_split=0.2, validation_data=(tmp_x_val, tmp_y_val))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_10 (GRU)                 (None, 21, 100)           30900     \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 21, 345)           34845     \n",
            "=================================================================\n",
            "Total params: 65,745\n",
            "Trainable params: 65,745\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 48s 634ms/step - loss: 4.5295 - val_loss: 2.5477\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 41s 573ms/step - loss: 2.4775 - val_loss: 2.2804\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 43s 592ms/step - loss: 2.2087 - val_loss: 1.9758\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 41s 568ms/step - loss: 1.9148 - val_loss: 1.7700\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 44s 610ms/step - loss: 1.7408 - val_loss: 1.6571\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 41s 568ms/step - loss: 1.6375 - val_loss: 1.5762\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 41s 572ms/step - loss: 1.5658 - val_loss: 1.5114\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 42s 578ms/step - loss: 1.5012 - val_loss: 1.4564\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 42s 588ms/step - loss: 1.4506 - val_loss: 1.4095\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 42s 584ms/step - loss: 1.4050 - val_loss: 1.3685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfReuFhcQWgy",
        "outputId": "74e1ead9-e09a-4212-acc7-7c629d581a23"
      },
      "source": [
        "history.history"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [3.5306386947631836,\n",
              "  2.416224718093872,\n",
              "  2.1343350410461426,\n",
              "  1.8652037382125854,\n",
              "  1.714542031288147,\n",
              "  1.6204372644424438,\n",
              "  1.5490201711654663,\n",
              "  1.489421010017395,\n",
              "  1.4386987686157227,\n",
              "  1.3952075242996216],\n",
              " 'val_loss': [2.5477161407470703,\n",
              "  2.2804393768310547,\n",
              "  1.9758328199386597,\n",
              "  1.7699960470199585,\n",
              "  1.6570539474487305,\n",
              "  1.576246738433838,\n",
              "  1.5114405155181885,\n",
              "  1.4564123153686523,\n",
              "  1.409471035003662,\n",
              "  1.3684992790222168]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbJUh5F0_Y9g",
        "outputId": "2267d7d6-c19e-4caa-8d71-b3070f44ce71"
      },
      "source": [
        "simple_rnn_model.evaluate()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80000, 21, 1)\n",
            "(80000, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-QfF-fk7WJY",
        "outputId": "fc351264-560c-405b-d41c-be555e7c4f25"
      },
      "source": [
        "index_to_words = {id: word for word, id in fr_vocab.items()}\n",
        "index_to_words[0] = '<pad>'\n",
        "print(index_to_words)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'est', 2: 'en', 3: 'il', 4: 'les', 5: 'mais', 6: 'et', 7: 'la', 8: 'parfois', 9: 'jamais', 10: 'le', 11: \"l'\", 12: 'généralement', 13: 'moins', 14: 'aimé', 15: 'au', 16: 'fruit', 17: 'préféré', 18: 'agréable', 19: 'froid', 20: 'son', 21: 'chaud', 22: 'de', 23: 'plus', 24: 'automne', 25: 'mois', 26: 'à', 27: 'elle', 28: 'citrons', 29: 'paris', 30: 'inde', 31: 'unis', 32: 'états', 33: 'france', 34: 'jersey', 35: 'new', 36: 'chine', 37: 'pendant', 38: 'pamplemousse', 39: 'mon', 40: 'votre', 41: 'juin', 42: 'printemps', 43: 'janvier', 44: 'hiver', 45: 'mars', 46: 'été', 47: 'mai', 48: 'septembre', 49: 'juillet', 50: 'avril', 51: 'novembre', 52: 'décembre', 53: 'février', 54: 'octobre', 55: 'aime', 56: 'août', 57: 'merveilleux', 58: 'relaxant', 59: 'doux', 60: 'humide', 61: 'notre', 62: 'californie', 63: 'sec', 64: 'leur', 65: 'occupé', 66: 'pluvieux', 67: 'calme', 68: 'beau', 69: 'habituellement', 70: 'pommes', 71: 'pêches', 72: 'oranges', 73: 'poires', 74: 'fraises', 75: 'bananes', 76: 'verts', 77: 'raisins', 78: 'mangues', 79: \"d'\", 80: 'mangue', 81: 'gel', 82: 'raisin', 83: 'pomme', 84: \"l'orange\", 85: 'citron', 86: 'chaux', 87: 'banane', 88: 'poire', 89: 'fraise', 90: 'pêche', 91: 'pas', 92: 'enneigée', 93: 'favori', 94: 'déteste', 95: 'gèle', 96: 'fruits', 97: 'voiture', 98: \"l'automne\", 99: 'ils', 100: \"n'aime\", 101: 'california', 102: 'neige', 103: 'fait', 104: 'belle', 105: 'ne', 106: 'vous', 107: 'nous', 108: 'des', 109: 'animal', 110: 'camion', 111: 'cours', 112: 'neigeux', 113: 'conduit', 114: 'prochain', 115: 'ce', 116: 'je', 117: 'tranquille', 118: 'a', 119: 'cher', 120: 'une', 121: 'cette', 122: 'était', 123: 'aller', 124: 'aiment', 125: 'chaude', 126: 'aimons', 127: \"n'aiment\", 128: \"n'aimez\", 129: 'leurs', 130: 'aimez', 131: 'sont', 132: 'détestons', 133: 'jaune', 134: 'rouge', 135: \"j'aime\", 136: 'visiter', 137: 'sèche', 138: 'occupée', 139: 'frisquet', 140: 'préférée', 141: 'animaux', 142: 'dernier', 143: 'aimait', 144: 'un', 145: 'conduisait', 146: 'que', 147: 'nouvelle', 148: 'vieille', 149: 'vu', 150: 'verte', 151: 'petite', 152: 'nos', 153: 'noire', 154: 'brillant', 155: 'blanche', 156: 'redouté', 157: 'pleut', 158: \"n'aimait\", 159: 'pamplemousses', 160: 'pense', 161: 'entre', 162: 'bleue', 163: 'nouveau', 164: 'traduire', 165: 'rouillée', 166: 'bleu', 167: 'se', 168: 'grande', 169: 'rouillé', 170: 'ses', 171: \"qu'il\", 172: 'blanc', 173: 'aux', 174: 'brillante', 175: 'préférés', 176: 'noir', 177: 'pluies', 178: 'envisage', 179: 'étaient', 180: 'va', 181: 'rendre', 182: 'vert', 183: 'vieux', 184: 'petit', 185: 'espagnol', 186: 'portugais', 187: 'chinois', 188: 'anglais', 189: 'français', 190: 'glaciales', 191: 'mes', 192: 'cet', 193: 'automobile', 194: 'traduction', 195: 'mouillé', 196: 'difficile', 197: 'amusant', 198: 'facile', 199: 'comme', 200: 'gros', 201: 'souris', 202: 'pourrait', 203: 'voulait', 204: 'veut', 205: 'pourquoi', 206: 'aimés', 207: 'prévois', 208: 'prévoyons', 209: 'vos', 210: 'intention', 211: 'clémentes', 212: 'ont', 213: 'chat', 214: 'requin', 215: 'cheval', 216: 'chien', 217: 'singe', 218: 'lion', 219: 'ours', 220: 'lapin', 221: 'serpent', 222: 'redoutés', 223: 'allé', 224: 'grosse', 225: 'pluie', 226: 'trop', 227: 'monde', 228: 'maillot', 229: 'vont', 230: 'volant', 231: 'avez', 232: 'i', 233: 'allés', 234: 'allée', 235: 'quand', 236: 'oiseau', 237: 'éléphant', 238: 'pourraient', 239: 'voulaient', 240: 'veulent', 241: 'détendre', 242: 'aimée', 243: 'magnifique', 244: \"l'automobile\", 245: \"n'aimons\", 246: 'gelé', 247: 'détestait', 248: 'grand', 249: 'bien', 250: 'vers', 251: 'prévoient', 252: 'prévoit', 253: 'lui', 254: 'visite', 255: 'comment', 256: 'éléphants', 257: 'chevaux', 258: 'chiens', 259: \"l'éléphant\", 260: \"l'oiseau\", 261: 'requins', 262: \"l'ours\", 263: 'serpents', 264: 'chats', 265: 'lapins', 266: 'singes', 267: 'oiseaux', 268: 'lions', 269: 'légère', 270: 'cépage', 271: 'pensez', 272: 'tour', 273: 'eiffel', 274: \"l'épicerie\", 275: 'terrain', 276: 'football', 277: 'lac', 278: \"l'école\", 279: \"l'animal\", 280: \"n'est\", 281: 'allons', 282: 'allez', 283: 'peu', 284: 'pousse', 285: 'du', 286: 'temps', 287: 'at', 288: 'rouille', 289: 'sur', 290: \"qu'elle\", 291: 'petites', 292: 'dernière', 293: 'êtes', 294: 'vais', 295: 'voudrait', 296: 'proches', 297: 'frais', 298: 'manguiers', 299: 'avons', 300: 't', 301: 'porcelaine', 302: 'détestez', 303: \"c'est\", 304: 'grandes', 305: 'préférées', 306: 'douce', 307: 'durant', 308: 'congélation', 309: 'plaît', 310: 'où', 311: 'dans', 312: 'voulez', 313: 'aimeraient', 314: \"n'a\", 315: 'petits', 316: 'grands', 317: 'limes', 318: 'envisagent', 319: 'grosses', 320: 'bénigne', 321: 'mouillée', 322: 'enneigé', 323: 'moindres', 324: 'conduite', 325: 'gelés', 326: 'tout', 327: 'etats', 328: \"n'êtes\", 329: 'vit', 330: 'ressort', 331: 'détend', 332: 'redoutée', 333: 'tu', 334: 'qui', 335: 'traduis', 336: 'apprécié', 337: 'allions', 338: 'trouvé', 339: 'as', 340: 'faire', 341: 'favoris', 342: 'souvent', 343: 'es', 344: 'moteur', 0: '<pad>'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xHAjmwffTLE",
        "outputId": "9562ac18-6b86-45b5-b055-69977954cd17"
      },
      "source": [
        "tmp_x_test = preproc_en_test.reshape((preproc_en_test.shape[-2],-1, 1))\n",
        "tmp_y_test = preproc_fr_test.reshape((preproc_fr_test.shape[-2],-1, 1))\n",
        "prediction = simple_rnn_model.predict(tmp_x[:1])[0]\n",
        "print(np.argmax(prediction, 1))\n",
        "string = []\n",
        "for idx in np.argmax(prediction, 1):\n",
        "  string.append(index_to_words[idx])\n",
        "print(string)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 7 33  1  8  8  2 25  5  3  1  1  2  2  0  0  0  0  0  0  0  0]\n",
            "['la', 'france', 'est', 'parfois', 'parfois', 'en', 'mois', 'mais', 'il', 'est', 'est', 'en', 'en', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b4y3JxyiAfW",
        "outputId": "c589daf1-4a15-44d3-962f-b162344629b6"
      },
      "source": [
        "result = simple_rnn_model.evaluate(tmp_x_test, tmp_y_test)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 11s 11ms/step - loss: 2.0367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csAxsG3D9115",
        "outputId": "0649e73c-5a08-49d3-d167-0225519ab1a2"
      },
      "source": [
        "print(result)\n",
        "#print(tmp_y_test.shape)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0366780757904053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9SLBf5j-D8a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}